"""
íŒŒì¸íŠœë‹ìš© QA ë°ì´í„°ì…‹ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (GEMINI 2.5 pro ì‚¬ìš©)
ì•½ê´€ ì²­í¬ë¥¼ Contextë¡œ í¬í•¨í•˜ì—¬ "ë¬¸ì„œë¥¼ ë³´ê³  ë‹µë³€í•˜ëŠ”" í•™ìŠµ ë°ì´í„° ìƒì„±
GEMINI 2.5 proì˜ ìš°ìˆ˜í•œ í•œêµ­ì–´ ì„±ëŠ¥ê³¼ í™˜ê° ê°ì†Œ ê¸°ëŠ¥ í™œìš©
"""

import json
import random
import argparse
import os
import time
import requests
from pathlib import Path
from tqdm import tqdm
import google.generativeai as genai
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„)
env_paths = [
    '/home/pencilfoxs/00_new/.env2',  # ìš°ì„ ìˆœìœ„ 1
    '/home/pencilfoxs/PJ/.env2'        # ìš°ì„ ìˆœìœ„ 2
]

env_path = None
for path in env_paths:
    if os.path.exists(path):
        env_path = path
        load_dotenv(path)
        break

if not env_path:
    print(f"âš ï¸  í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {env_paths}")

# ì„¤ì •
DATA_PATH = "/home/pencilfoxs/0_Insurance_PF/01_Preprocessing/chunked_data.jsonl"
OUTPUT_PATH = "/home/pencilfoxs/0_Insurance_PF/05_FineTuning/train_dataset_rag_gemini.json"

# API í‚¤ ì°¾ê¸° (ìš°ì„ ìˆœìœ„: GOOGLE_API_KEY_19 > GOOGLE_API_KEY_2 > GOOGLE_API_KEY > GOOGLE_AI_STUDIO_API_KEY)
GEMINI_API_KEY = os.getenv('GOOGLE_API_KEY_19') or os.getenv('GOOGLE_API_KEY_2') or os.getenv('GOOGLE_API_KEY') or os.getenv('GOOGLE_AI_STUDIO_API_KEY')

# API í‚¤ê°€ ì—†ìœ¼ë©´ ì§ì ‘ íŒŒì¼ì—ì„œ ì½ê¸° ì‹œë„
if not GEMINI_API_KEY and os.path.exists(env_path):
    with open(env_path, 'r', encoding='utf-8') as f:
        for line in f:
            line_stripped = line.strip()
            # ì£¼ì„ì´ë‚˜ ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
            if not line_stripped or line_stripped.startswith('#'):
                continue
            
            # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ í‚¤ ì°¾ê¸°
            for key_name in ['GOOGLE_API_KEY_2', 'GOOGLE_API_KEY', 'GOOGLE_AI_STUDIO_API_KEY']:
                if key_name in line_stripped and '=' in line_stripped:
                    parts = line_stripped.split('=', 1)
                    if len(parts) == 2:
                        GEMINI_API_KEY = parts[1].strip()
                        # ì£¼ì„ ì œê±°
                        if '#' in GEMINI_API_KEY:
                            GEMINI_API_KEY = GEMINI_API_KEY.split('#')[0].strip()
                        print(f"âœ… {key_name} ì‚¬ìš©")
                        break
            if GEMINI_API_KEY:
                break

if not GEMINI_API_KEY:
    raise ValueError("GEMINI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env2 íŒŒì¼ì— GOOGLE_API_KEY_2, GOOGLE_API_KEY, ë˜ëŠ” GOOGLE_AI_STUDIO_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

print(f"âœ… API í‚¤ ë¡œë“œ ì™„ë£Œ (ê¸¸ì´: {len(GEMINI_API_KEY)}ì)")


def init_gemini():
    """GEMINI ëª¨ë¸ ì´ˆê¸°í™” (SDK ìš°ì„ , REST API í´ë°±)"""
    print("Initializing GEMINI...")
    
    # SDK ë°©ì‹ ë¨¼ì € ì‹œë„ (ë” ì•ˆì •ì )
    try:
        model = init_gemini_sdk()
        print("âœ… GEMINI SDK ì´ˆê¸°í™” ì„±ê³µ")
        return model
    except Exception as e_sdk:
        print(f"âš ï¸  SDK ë°©ì‹ ì‹¤íŒ¨: {e_sdk}")
        print("REST API ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„...")
        
        # REST API ì—”ë“œí¬ì¸íŠ¸ ì„¤ì • (v1beta ì‚¬ìš©, gemini-2.5-flash ì‚¬ìš©)
        model_name = 'gemini-2.5-flash'
        api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={GEMINI_API_KEY}"
        
        print(f"âœ… Using model: {model_name} (REST API)")
        
        # í…ŒìŠ¤íŠ¸ ìš”ì²­
        test_payload = {
            "contents": [{
                "parts": [{"text": "í…ŒìŠ¤íŠ¸"}]
            }]
        }
        
        try:
            response = requests.post(api_url, json=test_payload, timeout=10)
            if response.status_code == 200:
                result = response.json()
                # ì‘ë‹µ êµ¬ì¡° í™•ì¸
                if 'candidates' in result and len(result['candidates']) > 0:
                    candidate = result['candidates'][0]
                    if 'content' in candidate and 'parts' in candidate['content']:
                        print("âœ… GEMINI API ì—°ê²° ì„±ê³µ (REST API ì‚¬ìš©)")
                        return {'api_url': api_url, 'api_key': GEMINI_API_KEY}
                    else:
                        print(f"âš ï¸  REST API ì‘ë‹µ êµ¬ì¡° ë¬¸ì œ: {list(candidate.keys())}")
                        raise ValueError("REST API ì‘ë‹µ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤.")
                else:
                    raise ValueError("REST API ì‘ë‹µì— candidatesê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print(f"âš ï¸  API ì‘ë‹µ ì½”ë“œ: {response.status_code}")
                print(f"   ì‘ë‹µ: {response.text[:200]}")
                raise ValueError(f"REST API ì—°ê²° ì‹¤íŒ¨: {response.status_code}")
        except Exception as e_rest:
            print(f"âš ï¸  REST API ì‹¤íŒ¨: {e_rest}")
            raise ValueError("SDKì™€ REST API ëª¨ë‘ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


def init_gemini_sdk():
    """GEMINI SDK ë°©ì‹ ì´ˆê¸°í™”"""
    genai.configure(api_key=GEMINI_API_KEY)
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìˆœì„œëŒ€ë¡œ ì‹œë„ (ìµœì‹  ëª¨ë¸ ìš°ì„ )
    model_candidates = ['gemini-2.5-flash', 'gemini-2.5-pro', 'gemini-2.0-flash', 'gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-pro']
    
    for candidate in model_candidates:
        try:
            model = genai.GenerativeModel(
                candidate,
                generation_config={
                    'temperature': 0.7,
                    'top_p': 0.9,
                    'top_k': 40,
                    'max_output_tokens': 2000,  # í† í° ì œí•œ ëŒ€í­ ì¦ê°€ (1000 -> 2000)
                }
            )
            test_response = model.generate_content("test")
            if test_response and test_response.text:
                print(f"âœ… {candidate} ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ (SDK)")
                return model
        except Exception as e:
            if '404' not in str(e) and '403' not in str(e):
                print(f"âš ï¸  {candidate} - {str(e)[:60]}")
            continue
    
    raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ GEMINI ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")


def generate_qa_pair_rest(chunk_text: str, api_config, max_retries: int = 3, i: int = 0) -> dict | None:
    """REST APIë¥¼ ì‚¬ìš©í•œ QA ìŒ ìƒì„±"""
    prompt = f"""### ì§€ì‹œ
ë‹¹ì‹ ì€ ë³´í—˜ ì•½ê´€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ [ë³´í—˜ ì•½ê´€] ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ì¼ë°˜ ê³ ê°ì´ ì‹¤ì œë¡œ ë¬¼ì–´ë³¼ ë²•í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ê³¼ ê·¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.

[ìš”êµ¬ì‚¬í•­]
1. ì§ˆë¬¸: ê³ ê°ì´ ì‹¤ì œë¡œ ë¬¼ì–´ë³¼ ë²•í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ (ì˜ˆ: "ì´ê±° ë³´ìƒ ë˜ë‚˜ìš”?", "ì¹¨ìˆ˜ëëŠ”ë° ì–´ë–¡í•˜ì£ ?")
2. ë‹µë³€: ë°˜ë“œì‹œ ì œê³µëœ ì•½ê´€ ë‚´ìš©ì— ê¸°ë°˜í•˜ì—¬ ë‹µë³€. ì•½ê´€ì— ëª…ì‹œëœ ì¡°í•­ì´ë‚˜ ê·¼ê±°ë¥¼ ì–¸ê¸‰í•˜ë©° ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª….
   - ì•½ê´€ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
   - ë‰´ìŠ¤ ê¸°ì‚¬, ê´‘ê³ , ì™¸êµ­ì–´ ë“± ë¬´ê´€í•œ ë‚´ìš©ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
   - ë‹µë³€ì€ ì „ë¬¸ì ì´ê³  ì •í™•í•´ì•¼ í•©ë‹ˆë‹¤.
3. í˜•ì‹: ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
ì§ˆë¬¸: [ì§ˆë¬¸ë‚´ìš©]
ë‹µë³€: [ì•½ê´€ì„ ì°¸ì¡°í•œ ë‹µë³€ë‚´ìš©]

### ë³´í—˜ ì•½ê´€ ë‚´ìš©
{chunk_text[:1500]}

### ìƒì„± ê²°ê³¼
"""
    
    for attempt in range(max_retries):
        try:
            payload = {
                "contents": [{
                    "parts": [{"text": prompt}]
                }],
                "generationConfig": {
                    "temperature": 0.7,
                    "topP": 0.9,
                    "topK": 40,
                    "maxOutputTokens": 2000,  # 1000 -> 2000ìœ¼ë¡œ ì¦ê°€ (SDKì™€ ë™ì¼í•˜ê²Œ)
                }
            }
            
            response = requests.post(api_config['api_url'], json=payload, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                # ì•ˆì „í•œ ì‘ë‹µ íŒŒì‹±
                if 'candidates' in result and len(result['candidates']) > 0:
                    candidate = result['candidates'][0]
                    
                    # finishReason í™•ì¸
                    finish_reason = candidate.get('finishReason', '')
                    if finish_reason == 'MAX_TOKENS':
                        print(f"âš ï¸  ì‘ë‹µì´ í† í° ì œí•œìœ¼ë¡œ ì˜ë ¸ìŠµë‹ˆë‹¤. maxOutputTokensë¥¼ ëŠ˜ë ¤ì£¼ì„¸ìš”.")
                    
                    # í‘œì¤€ ê²½ë¡œ: candidates[0].content.parts[0].text
                    if 'content' in candidate and 'parts' in candidate['content']:
                        if len(candidate['content']['parts']) > 0:
                            part = candidate['content']['parts'][0]
                            if 'text' in part:
                                output = part['text']
                                return parse_qa_output(output, chunk_text)
                    
                    # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ì‹œë„ì—ì„œë§Œ êµ¬ì¡° ì¶œë ¥
                    if attempt == 0 and i == 0:
                        print(f"ğŸ” ì‘ë‹µ êµ¬ì¡° ë””ë²„ê¹…:")
                        print(f"   candidate keys: {list(candidate.keys())}")
                        print(f"   finishReason: {finish_reason}")
                        if 'content' in candidate:
                            print(f"   content keys: {list(candidate['content'].keys())}")
                            if 'parts' not in candidate['content']:
                                print(f"   âš ï¸  'parts' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ì‘ë‹µ:")
                                print(f"   {json.dumps(candidate, ensure_ascii=False, indent=2)[:800]}")
                    
                    # ëŒ€ì²´ ê²½ë¡œ 1: candidates[0].text
                    if 'text' in candidate:
                        output = candidate['text']
                        return parse_qa_output(output, chunk_text)
                    
                    # ëŒ€ì²´ ê²½ë¡œ 2: candidates[0].output ë˜ëŠ” candidates[0].content
                    if 'output' in candidate:
                        output = candidate['output']
                        return parse_qa_output(output, chunk_text)
                    
                    # ë§ˆì§€ë§‰ ì‹œë„: contentê°€ ë¬¸ìì—´ì¸ ê²½ìš°
                    if 'content' in candidate and isinstance(candidate['content'], str):
                        output = candidate['content']
                        return parse_qa_output(output, chunk_text)
                
                # candidatesê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš°
                if attempt == 0:
                    print(f"âš ï¸  ì‘ë‹µ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤: {list(result.keys())}")
                    if 'candidates' in result:
                        print(f"   candidates ê°œìˆ˜: {len(result.get('candidates', []))}")
            else:
                print(f"API ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}): {response.status_code} - {response.text[:200]}")
                time.sleep(2)
        except KeyError as e:
            print(f"Attempt {attempt + 1} failed (KeyError): {e}")
            # ë””ë²„ê¹…ì„ ìœ„í•´ ì‘ë‹µ ì¶œë ¥
            if response.status_code == 200:
                try:
                    result = response.json()
                    print(f"   ì‘ë‹µ êµ¬ì¡°: {list(result.keys())}")
                    if 'candidates' in result:
                        print(f"   candidates[0] êµ¬ì¡°: {list(result['candidates'][0].keys()) if result['candidates'] else 'empty'}")
                except:
                    pass
            time.sleep(2)
        except Exception as e:
            print(f"Attempt {attempt + 1} failed: {e}")
            time.sleep(2)
    
    return None


def generate_qa_pair(chunk_text: str, model, max_retries: int = 3) -> dict | None:
    """
    ì•½ê´€ ì²­í¬ë¥¼ Contextë¡œ í¬í•¨í•˜ì—¬ RAG ìŠ¤íƒ€ì¼ì˜ QA ìŒ ìƒì„± (GEMINI ì‚¬ìš©)
    
    Returns:
        {"instruction": ..., "input": ..., "output": ...} í˜•íƒœì˜ dict ë˜ëŠ” None
    """
    # RAG ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸: ì•½ê´€ì„ ë³´ê³  ë‹µë³€í•˜ëŠ” íŒ¨í„´ í•™ìŠµ
    prompt = f"""### ì§€ì‹œ
ë‹¹ì‹ ì€ ë³´í—˜ ì•½ê´€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ [ë³´í—˜ ì•½ê´€] ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ì¼ë°˜ ê³ ê°ì´ ì‹¤ì œë¡œ ë¬¼ì–´ë³¼ ë²•í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ê³¼ ê·¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.

[ìš”êµ¬ì‚¬í•­]
1. ì§ˆë¬¸: ê³ ê°ì´ ì‹¤ì œë¡œ ë¬¼ì–´ë³¼ ë²•í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ (ì˜ˆ: "ì´ê±° ë³´ìƒ ë˜ë‚˜ìš”?", "ì¹¨ìˆ˜ëëŠ”ë° ì–´ë–¡í•˜ì£ ?")
2. ë‹µë³€: ë°˜ë“œì‹œ ì œê³µëœ ì•½ê´€ ë‚´ìš©ì— ê¸°ë°˜í•˜ì—¬ ë‹µë³€. ì•½ê´€ì— ëª…ì‹œëœ ì¡°í•­ì´ë‚˜ ê·¼ê±°ë¥¼ ì–¸ê¸‰í•˜ë©° ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª….
   - ì•½ê´€ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
   - ë‰´ìŠ¤ ê¸°ì‚¬, ê´‘ê³ , ì™¸êµ­ì–´ ë“± ë¬´ê´€í•œ ë‚´ìš©ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
   - ë‹µë³€ì€ ì „ë¬¸ì ì´ê³  ì •í™•í•´ì•¼ í•©ë‹ˆë‹¤.
3. í˜•ì‹: ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
ì§ˆë¬¸: [ì§ˆë¬¸ë‚´ìš©]
ë‹µë³€: [ì•½ê´€ì„ ì°¸ì¡°í•œ ë‹µë³€ë‚´ìš©]

### ë³´í—˜ ì•½ê´€ ë‚´ìš©
{chunk_text[:1500]}

### ìƒì„± ê²°ê³¼
"""
    
    for attempt in range(max_retries):
        try:
            # GEMINI API í˜¸ì¶œ
            response = model.generate_content(prompt)
            
            # finish_reason í™•ì¸
            if response.candidates and len(response.candidates) > 0:
                candidate = response.candidates[0]
                finish_reason = candidate.finish_reason
                
                if finish_reason == 2:  # MAX_TOKENS
                    print(f"âš ï¸  ì‘ë‹µì´ í† í° ì œí•œìœ¼ë¡œ ì˜ë ¸ìŠµë‹ˆë‹¤. max_output_tokensë¥¼ ëŠ˜ë ¤ì£¼ì„¸ìš”.")
                    # ì¼ë‹¨ ì‹œë„í•´ë³´ê¸°
                    try:
                        output = response.text
                    except:
                        # partsì—ì„œ ì§ì ‘ ì¶”ì¶œ ì‹œë„
                        if candidate.content and candidate.content.parts:
                            output = candidate.content.parts[0].text
                        else:
                            print(f"âš ï¸  ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì¬ì‹œë„...")
                            time.sleep(2)
                            continue
                else:
                    output = response.text
            else:
                print(f"âš ï¸  ì‘ë‹µì— candidatesê°€ ì—†ìŠµë‹ˆë‹¤. ì¬ì‹œë„...")
                time.sleep(2)
                continue
            
            # íŒŒì‹± í•¨ìˆ˜ ì‚¬ìš©
            result = parse_qa_output(output, chunk_text)
            if result:
                return result
            else:
                print(f"âš ï¸  íŒŒì‹± ì‹¤íŒ¨ ë˜ëŠ” í™˜ê° ê°ì§€, ì¬ì‹œë„... (attempt {attempt + 1}/{max_retries})")
                time.sleep(1)
        except Exception as e:
            print(f"Attempt {attempt + 1} failed: {e}")
            time.sleep(2)
    
    return None


def parse_qa_output(output: str, chunk_text: str) -> dict | None:
    """ìƒì„±ëœ ì¶œë ¥ì—ì„œ ì§ˆë¬¸ê³¼ ë‹µë³€ íŒŒì‹±"""
    lines = output.strip().split('\n')
    question = None
    answer = None
    
    for line in lines:
        line = line.strip()
        if line.startswith('ì§ˆë¬¸:') or line.startswith('ì§ˆë¬¸ :'):
            question = line.replace('ì§ˆë¬¸:', '').replace('ì§ˆë¬¸ :', '').strip()
        elif line.startswith('ë‹µë³€:') or line.startswith('ë‹µë³€ :'):
            answer = line.replace('ë‹µë³€:', '').replace('ë‹µë³€ :', '').strip()
            # ë‹µë³€ì€ ì—¬ëŸ¬ ì¤„ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì´í›„ ì¤„ë“¤ë„ í¬í•¨
            answer_lines = [answer]
            idx = lines.index(line) + 1
            while idx < len(lines) and not lines[idx].strip().startswith(('ì§ˆë¬¸:', 'ë‹µë³€:', '###')):
                if lines[idx].strip():
                    answer_lines.append(lines[idx].strip())
                idx += 1
            answer = '\n'.join(answer_lines)
            break
    
    if question and answer:
        # Validation: í™˜ê° íŒ¨í„´ ì²´í¬
        hallucination_patterns = [
            "ì´ë²ˆì— ìƒˆë¡œ ë‚˜ì˜¨",
            "Este es",
            "Ich mÃ¶chte",
            "í‰ì°½ë™ê³„ì˜¬ë¦¼í”½",
            "ë§ˆë¼í†¤",
            "ì›ìë ¥",
            "ì•„ë‹ˆ í˜•",
            "ì‚¬ë‘í•´",
            "ã‚ã€ã‚‚ã†"
        ]
        
        has_hallucination = any(pattern in answer for pattern in hallucination_patterns)
        
        if has_hallucination:
            return None  # ì¬ì‹œë„ í•„ìš”
        
        # RAG ìŠ¤íƒ€ì¼ Instruction Tuning í¬ë§·
        return {
            "instruction": "ì•„ë˜ ì œê³µëœ [ë³´í—˜ì•½ê´€]ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. ì•½ê´€ì— ëª…ì‹œëœ ë‚´ìš©ì— ê·¼ê±°í•˜ì—¬ ë‹µë³€í•´ì•¼ í•˜ë©°, ì•½ê´€ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  'ì•½ê´€ì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.",
            "input": f"[ë³´í—˜ì•½ê´€]\n{chunk_text[:1500]}\n\nì§ˆë¬¸: {question}",
            "output": answer
        }
    
    return None


def load_chunks(jsonl_path: str, max_chunks: int = 600) -> list:
    """JSONL íŒŒì¼ì—ì„œ ì²­í¬ ë¡œë“œ (ëœë¤ ìƒ˜í”Œë§)"""
    chunks = []
    with open(jsonl_path, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                item = json.loads(line)
                chunk_text = item.get('text') or item.get('chunk') or item.get('content', '')
                if chunk_text and len(chunk_text) > 100:  # ë„ˆë¬´ ì§§ì€ ì²­í¬ ì œì™¸
                    chunks.append(chunk_text)
            except json.JSONDecodeError:
                continue
    
    # ëœë¤ ìƒ˜í”Œë§
    if len(chunks) > max_chunks:
        chunks = random.sample(chunks, max_chunks)
    
    return chunks


def format_for_training(data: list) -> list:
    """
    Instruction Tuning í¬ë§·ìœ¼ë¡œ ë³€í™˜ (RAG ìŠ¤íƒ€ì¼)
    ìµœì¢… í˜•íƒœ: "### ì§€ì‹œ\n{instruction}\n### ì…ë ¥\n{input}\n### ì¶œë ¥\n{output}<|end_of_text|>"
    EOS í† í°ì„ ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€í•˜ì—¬ ë°˜ë³µ ìƒì„± ë¬¸ì œ í•´ê²°
    """
    formatted = []
    for item in data:
        # EOS í† í° ëª…ì‹œì  ì¶”ê°€
        text = f"### ì§€ì‹œ\n{item['instruction']}\n### ì…ë ¥\n{item['input']}\n### ì¶œë ¥\n{item['output']}<|end_of_text|>"
        formatted.append({"text": text})
    return formatted


def main():
    parser = argparse.ArgumentParser(description="Generate RAG-style QA dataset using GEMINI 2.5 pro")
    parser.add_argument(
        "--num_samples",
        type=int,
        default=600,
        help="Number of QA pairs to generate (default: 600)"
    )
    parser.add_argument(
        "--output",
        default=OUTPUT_PATH,
        help="Output JSON file path"
    )
    parser.add_argument(
        "--resume",
        action="store_true",
        help="Resume from existing file (skip already generated samples)"
    )
    args = parser.parse_args()

    # ê¸°ì¡´ íŒŒì¼ì—ì„œ ì´ì–´ì„œ ìƒì„± (resume ì˜µì…˜)
    dataset = []
    start_idx = 0
    if args.resume and os.path.exists(args.output):
        try:
            with open(args.output, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
            
            # íŒŒì¼ í˜•ì‹ í™•ì¸: {"text": "..."} í˜•ì‹ì¸ì§€ {"instruction": ...} í˜•ì‹ì¸ì§€
            if existing_data and isinstance(existing_data[0], dict):
                if 'text' in existing_data[0]:
                    # ì´ë¯¸ í¬ë§·íŒ…ëœ í˜•ì‹ì´ë©´ ìƒ˜í”Œ ìˆ˜ë§Œ ì¹´ìš´íŠ¸
                    start_idx = len(existing_data)
                    print(f"âœ… ê¸°ì¡´ íŒŒì¼ì—ì„œ {start_idx}ê°œ ìƒ˜í”Œ í™•ì¸ (ì´ë¯¸ í¬ë§·íŒ…ë¨)")
                elif 'instruction' in existing_data[0]:
                    # ì›ë³¸ í˜•ì‹ì´ë©´ datasetì— ì¶”ê°€
                    dataset = existing_data
                    start_idx = len(dataset)
                    print(f"âœ… ê¸°ì¡´ íŒŒì¼ì—ì„œ {start_idx}ê°œ ìƒ˜í”Œ ë¡œë“œ ì™„ë£Œ")
                else:
                    start_idx = len(existing_data)
                    print(f"âœ… ê¸°ì¡´ íŒŒì¼ì—ì„œ {start_idx}ê°œ ìƒ˜í”Œ í™•ì¸")
            
            print(f"ğŸ“Š {args.num_samples - start_idx}ê°œ ì¶”ê°€ ìƒì„± ì˜ˆì •")
        except Exception as e:
            print(f"âš ï¸  ê¸°ì¡´ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤...")
            dataset = []
            start_idx = 0

    # 1. ì²­í¬ ë¡œë“œ
    print(f"Loading chunks from {DATA_PATH}...")
    chunks = load_chunks(DATA_PATH, max_chunks=args.num_samples * 2)  # ì—¬ìœ ìˆê²Œ ë¡œë“œ
    print(f"Loaded {len(chunks)} chunks")

    # 2. GEMINI ëª¨ë¸ ì´ˆê¸°í™”
    model = init_gemini()
    print("âœ… GEMINI 2.5 pro initialized")

    # 3. QA ìŒ ìƒì„± (RAG ìŠ¤íƒ€ì¼)
    remaining_samples = args.num_samples - start_idx
    if remaining_samples > 0:
        print(f"\nGenerating {remaining_samples} RAG-style QA pairs using GEMINI 2.5 pro...")
        if start_idx > 0:
            print(f"ğŸ’¡ ì´ì–´ì„œ ìƒì„±: {start_idx}ê°œ ì™„ë£Œ, {remaining_samples}ê°œ ë‚¨ìŒ")
        print("ğŸ’¡ ê°œì„  ì‚¬í•­: GEMINIì˜ ìš°ìˆ˜í•œ í•œêµ­ì–´ ì„±ëŠ¥ê³¼ í™˜ê° ê°ì†Œ ê¸°ëŠ¥ í™œìš©")
    else:
        print(f"\nâœ… ì´ë¯¸ {args.num_samples}ê°œ ìƒ˜í”Œì´ ìƒì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
        return
    
    start_time = time.time()
    
    # ì´ì–´ì„œ ìƒì„±í•  ì²­í¬ë§Œ ì„ íƒ
    chunks_to_process = chunks[start_idx:start_idx + remaining_samples]
    
    for i, chunk in enumerate(tqdm(chunks_to_process, desc="Generating", initial=start_idx, total=args.num_samples)):
        # chunkê°€ dictì¸ ê²½ìš° 'text' í‚¤ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        chunk_text = chunk['text'] if isinstance(chunk, dict) else chunk
        
        # REST API ë˜ëŠ” SDK ë°©ì‹ì— ë”°ë¼ í˜¸ì¶œ
        if isinstance(model, dict):
            qa_pair = generate_qa_pair_rest(chunk_text, model, i=i)
        else:
            qa_pair = generate_qa_pair(chunk_text, model)
        
        if qa_pair:
            dataset.append(qa_pair)
        
        # ì¤‘ê°„ ì €ì¥ (50ê°œë§ˆë‹¤)
        if (start_idx + i + 1) % 50 == 0:
            # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œí•´ì„œ ë³‘í•©
            if args.resume and os.path.exists(args.output):
                try:
                    with open(args.output, 'r', encoding='utf-8') as f:
                        existing_data = json.load(f)
                    # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„° ë³‘í•© (ì¤‘ë³µ ì œê±°)
                    all_data = existing_data + dataset
                    formatted_dataset = format_for_training(all_data)
                except:
                    formatted_dataset = format_for_training(dataset)
            else:
                formatted_dataset = format_for_training(dataset)
            
            output_path = Path(args.output)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(formatted_dataset, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {len(formatted_dataset)}ê°œ ì €ì¥ë¨")
        
        # API rate limit ë°©ì§€ (ìš”ì²­ ê°„ ë”œë ˆì´)
        time.sleep(0.5)
    
    elapsed_time = time.time() - start_time
    
    print(f"\nGenerated {len(dataset)} valid QA pairs")
    print(f"â±ï¸  ì†Œìš” ì‹œê°„: {elapsed_time/60:.1f}ë¶„")
    print(f"ğŸ“Š ì„±ê³µë¥ : {len(dataset)/remaining_samples*100:.1f}%")

    # 4. Instruction Tuning í¬ë§·ìœ¼ë¡œ ë³€í™˜ (EOS í† í° í¬í•¨)
    # ê¸°ì¡´ íŒŒì¼ê³¼ ë³‘í•©
    if args.resume and os.path.exists(args.output):
        try:
            with open(args.output, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
            # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„° ë³‘í•©
            all_data = existing_data + dataset
            formatted_dataset = format_for_training(all_data)
            print(f"âœ… ê¸°ì¡´ {len(existing_data)}ê°œ + ìƒˆë¡œ ìƒì„± {len(dataset)}ê°œ = ì´ {len(formatted_dataset)}ê°œ")
        except Exception as e:
            print(f"âš ï¸  ê¸°ì¡´ íŒŒì¼ ë³‘í•© ì‹¤íŒ¨: {e}")
            formatted_dataset = format_for_training(dataset)
    else:
        formatted_dataset = format_for_training(dataset)

    # 5. ì €ì¥
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(formatted_dataset, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… Dataset saved to {output_path}")
    print(f"Total samples: {len(formatted_dataset)}")
    print("\nğŸ“Š ìƒ˜í”Œ ë°ì´í„°:")
    if formatted_dataset:
        print(json.dumps(formatted_dataset[0], ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()

