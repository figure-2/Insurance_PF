# ğŸ”§ íŒŒì¸íŠœë‹ ì „ëµ ê¸°ìˆ  ëª…ì„¸ì„œ

**ì‘ì„± ì¼ì‹œ:** 2025-11-22 06:15 (KST)  
**ìµœì¢… ì—…ë°ì´íŠ¸:** 2025-11-24 00:50 (KST)  
**ì‘ì„±ì:** RAG ê°œë°œ ë‹´ë‹¹ì  
**ê´€ë ¨ ë‹¨ê³„:** 4.0 íŒŒì¸íŠœë‹ ë°ì´í„° ìƒì„± ë° QLoRA í•™ìŠµ, 6.0 RAG ìŠ¤íƒ€ì¼ ë°ì´í„°ì…‹ ì¬êµ¬ì¶• ë° ì¬í•™ìŠµ, 7.0 ì¶”ë¡  íŒŒë¼ë¯¸í„° ìµœì í™”

---

## 1. ê°œìš”

ë³¸ ë¬¸ì„œëŠ” ë³´í—˜ ì•½ê´€ RAG ì‹œìŠ¤í…œì˜ LLM íŒŒì¸íŠœë‹ì„ ìœ„í•œ ê¸°ìˆ ì  ìƒì„¸ ëª…ì„¸ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. QLoRA ë°©ë²•ë¡ ì„ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ë„ë©”ì¸ íŠ¹í™” ëª¨ë¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

---

## 2. ì•„í‚¤í…ì²˜

### 2.1 ì „ì²´ íŒŒì´í”„ë¼ì¸

```
ì•½ê´€ ì²­í¬ (chunked_data.jsonl)
    â†“
[Step 3] Self-Instruct ë°ì´í„° ìƒì„± (generate_data.py)
    â†“
QA ë°ì´í„°ì…‹ (train_dataset.json)
    â†“
[Step 4] QLoRA íŒŒì¸íŠœë‹ (train_qlora.py)
    â†“
Fine-tuned Model (Base + LoRA Adapter)
    â†“
[Step 5] í‰ê°€ (evaluate_final.py)
```

### 2.2 QLoRA êµ¬ì¡°

```
Base Model (beomi/Llama-3-Open-Ko-8B)
â”œâ”€â”€ 4-bit Quantization (NF4)
â”‚   â”œâ”€â”€ Linear Layers: q_proj, k_proj, v_proj, o_proj
â”‚   â””â”€â”€ Frozen (í•™ìŠµ ì•ˆ í•¨)
â””â”€â”€ LoRA Adapters (Trainable)
    â”œâ”€â”€ Rank: 16
    â”œâ”€â”€ Alpha: 32
    â””â”€â”€ Dropout: 0.05
```

---

## 3. ë°ì´í„° ìŠ¤í‚¤ë§ˆ

### 3.1 ì…ë ¥ ë°ì´í„° (ì•½ê´€ ì²­í¬)

**íŒŒì¼:** `01_Preprocessing/chunked_data.jsonl`

```json
{
  "chunk_id": "string",
  "text": "string (ì•½ê´€ ë‚´ìš©)",
  "metadata": {
    "source": "string",
    "company": "string",
    "breadcrumbs": "string",
    "token_count": int,
    "policy_type": "string"
  }
}
```

### 3.2 ìƒì„± ë°ì´í„° (QA ìŒ) - Phase 1

**íŒŒì¼:** `05_FineTuning/train_dataset.json` (491ê°œ)

```json
[
  {
    "text": "### ì§€ì‹œ\n{instruction}\n### ì…ë ¥\n{input}\n### ì¶œë ¥\n{output}"
  }
]
```

**í•„ë“œ ì„¤ëª…:**
- `instruction`: ì‚¬ìš©ì ì§ˆë¬¸
- `input`: ì•½ê´€ ë‚´ìš© (ìµœëŒ€ 500ì)
- `output`: ëª¨ë¸ì´ ìƒì„±í•´ì•¼ í•  ë‹µë³€

**ë¬¸ì œì :**
- ë‹¨ìˆœíˆ ì§ˆë¬¸-ë‹µë³€ ìŒìœ¼ë¡œë§Œ êµ¬ì„±ë˜ì–´ ìˆì–´, ëª¨ë¸ì´ "ì§€ì‹ ì•”ê¸°"ë¥¼ ì‹œë„í•¨
- RAG ì‹œìŠ¤í…œì—ì„œ í•„ìš”í•œ "ë¬¸ì„œë¥¼ ë³´ê³  ë‹µë³€í•˜ëŠ” ëŠ¥ë ¥"ì„ í•™ìŠµí•˜ì§€ ëª»í•¨

### 3.3 RAG ìŠ¤íƒ€ì¼ ë°ì´í„°ì…‹ (Phase 2) - ìµœì¢… ì±„íƒ

**íŒŒì¼:** `05_FineTuning/train_dataset_rag.json` (478ê°œ)

**ë°ì´í„° í¬ë§·:**
```json
[
  {
    "text": "### ì§€ì‹œ\nì•„ë˜ ì œê³µëœ [ë³´í—˜ì•½ê´€]ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. ì•½ê´€ì— ëª…ì‹œëœ ë‚´ìš©ì— ê·¼ê±°í•˜ì—¬ ë‹µë³€í•´ì•¼ í•˜ë©°, ì•½ê´€ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  'ì•½ê´€ì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.\n### ì…ë ¥\n[ë³´í—˜ì•½ê´€]\n{ì•½ê´€ ì¡°í•­ ë‚´ìš©}\n\nì§ˆë¬¸: {ì§ˆë¬¸}\n### ì¶œë ¥\n{ì•½ê´€ì„ ì°¸ì¡°í•œ ë‹µë³€}<|end_of_text|>"
  }
]
```

**ì£¼ìš” íŠ¹ì§•:**
1. **ëª…ì‹œì  ì§€ì‹œ (Instruction):** "ì•½ê´€ì— ì—†ëŠ” ë‚´ìš©ì€ ë‹µí•˜ì§€ ë§ë¼"ëŠ” ì§€ì‹œë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
2. **Context í¬í•¨:** ì•½ê´€ ì¡°í•­ì„ Inputì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í•˜ì—¬, ëª¨ë¸ì´ "ë¬¸ì„œë¥¼ ë³´ê³  ë‹µë³€í•˜ëŠ”" íŒ¨í„´ í•™ìŠµ
3. **EOS í† í° ëª…ì‹œ:** ë‹µë³€ ëì— `<|end_of_text|>` í† í°ì„ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í•˜ì—¬ ì¢…ë£Œ íŒ¨í„´ í•™ìŠµ
4. **ì•½ê´€ ì¸ìš© ìœ ë„:** ë‹µë³€ í˜•ì‹ì— "ì œNì¡°ì— ë”°ë¥´ë©´..." ê°™ì€ íŒ¨í„´ì„ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„

**ìƒì„± íŒŒì´í”„ë¼ì¸:**
1. ì•½ê´€ ì²­í¬ë¥¼ Contextë¡œ í¬í•¨
2. Base Modelì—ê²Œ "ì•½ê´€ì„ ë³´ê³  ì§ˆë¬¸-ë‹µë³€ ìŒ ìƒì„±" ìš”ì²­
3. Validation: ë‹µë³€ì´ í•´ë‹¹ ì•½ê´€ ë‚´ìš©ì„ í¬í•¨í•˜ëŠ”ì§€ ê²€ì¦
4. EOS í† í° ì¶”ê°€ ë° í¬ë§·íŒ…

**ìƒì„± í†µê³„:**
- ëª©í‘œ: 500ê°œ
- ì‹¤ì œ ìƒì„±: 478ê°œ (95.6%)
- ìƒì„± ì‹œê°„: ì•½ 5ì‹œê°„ 36ë¶„ (í‰ê·  42ì´ˆ/ìƒ˜í”Œ)
- íŒŒì¼ í¬ê¸°: 1.4MB

### 3.4 í•™ìŠµ ë°ì´í„° í¬ë§· ë³€í™˜

**Phase 1 (ë‹¨ìˆœ QA):**
```python
def format_for_training(data: list) -> list:
    formatted = []
    for item in data:
        text = f"### ì§€ì‹œ\n{item['instruction']}\n### ì…ë ¥\n{item['input']}\n### ì¶œë ¥\n{item['output']}"
        formatted.append({"text": text})
    return formatted
```

**Phase 2 (RAG ìŠ¤íƒ€ì¼):**
```python
def formatting_func(example):
    # ë°ì´í„°ì— ì´ë¯¸ EOS í† í°ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    text = example["text"]
    # EOS í† í°ì´ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if "<|end_of_text|>" in text:
        pass  # ì´ë¯¸ í¬í•¨ë¨
    return text
```

---

## 4. ëª¨ë¸ ì„¤ì •

### 4.1 Base Model

- **ëª¨ë¸ëª…:** `beomi/Llama-3-Open-Ko-8B`
- **ì•„í‚¤í…ì²˜:** Llama-3 (8B parameters)
- **ì–‘ìí™”:** 4-bit NF4 (BitsAndBytesConfig)
- **Device:** CUDA (auto)

### 4.2 LoRA ì„¤ì •

```python
LoraConfig(
    r=16,                    # LoRA rank
    lora_alpha=32,           # LoRA alpha (scaling factor)
    target_modules=[          # ì ìš©í•  ë ˆì´ì–´
        "q_proj",
        "k_proj", 
        "v_proj",
        "o_proj"
    ],
    lora_dropout=0.05,       # Dropout rate
    bias="none",             # Bias í•™ìŠµ ì•ˆ í•¨
    task_type="CAUSAL_LM"    # Causal Language Modeling
)
```

### 4.3 í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°

```python
TrainingArguments(
    per_device_train_batch_size=2,
    gradient_accumulation_steps=4,    # Effective batch size = 8
    max_steps=200,
    learning_rate=2e-4,
    fp16=True,                        # Mixed precision
    logging_steps=10,
    save_steps=50,
    optim="paged_adamw_32bit",       # ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì˜µí‹°ë§ˆì´ì €
    warmup_steps=10
)
```

---

## 5. êµ¬í˜„ ìƒì„¸

### 5.1 ë°ì´í„° ìƒì„± - Phase 1 (`generate_data.py`)

**ì£¼ìš” í•¨ìˆ˜:**

1. **`load_4bit_model(model_name: str)`**
   - 4-bit ì–‘ìí™” ëª¨ë¸ ë¡œë“œ
   - BitsAndBytesConfig ì„¤ì •
   - Pipeline ìƒì„±

2. **`generate_qa_pair(chunk_text: str, pipe)`**
   - ì•½ê´€ ì²­í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ QA ìŒ ìƒì„±
   - í”„ë¡¬í”„íŠ¸: "ì•½ê´€ ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë§Œë“¤ì–´ì¤˜"
   - íŒŒì‹±: "ì§ˆë¬¸:", "ë‹µë³€:" í‚¤ì›Œë“œë¡œ ì¶”ì¶œ

3. **`format_for_training(data: list)`**
   - Instruction Tuning í¬ë§·ìœ¼ë¡œ ë³€í™˜

### 5.2 ë°ì´í„° ìƒì„± - Phase 2 (`generate_data_v2.py`) - ìµœì¢… ì±„íƒ

**ì£¼ìš” í•¨ìˆ˜:**

1. **`load_4bit_model(model_name: str)`**
   - 4-bit ì–‘ìí™” ëª¨ë¸ ë¡œë“œ (ë°ì´í„° ìƒì„±ìš©)
   - BitsAndBytesConfig ì„¤ì •
   - Pipeline ìƒì„±

2. **`generate_qa_pair(chunk_text: str, pipe, max_retries: int = 3)`**
   - **RAG ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸:** ì•½ê´€ì„ Contextë¡œ í¬í•¨í•˜ì—¬ "ì•½ê´€ì„ ë³´ê³  ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ”" íŒ¨í„´ ìƒì„±
   - í”„ë¡¬í”„íŠ¸ êµ¬ì¡°:
     ```
     ### ì§€ì‹œ
     ë‹¹ì‹ ì€ ë³´í—˜ ì•½ê´€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ [ë³´í—˜ ì•½ê´€] ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ...
     [ìš”êµ¬ì‚¬í•­]
     1. ì§ˆë¬¸: ê³ ê°ì´ ì‹¤ì œë¡œ ë¬¼ì–´ë³¼ ë²•í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸
     2. ë‹µë³€: ë°˜ë“œì‹œ ì œê³µëœ ì•½ê´€ ë‚´ìš©ì— ê¸°ë°˜í•˜ì—¬ ë‹µë³€. ì•½ê´€ì— ëª…ì‹œëœ ì¡°í•­ì´ë‚˜ ê·¼ê±°ë¥¼ ì–¸ê¸‰
     
     ### ë³´í—˜ ì•½ê´€ ë‚´ìš©
     {chunk_text}
     ```
   - Validation: ìƒì„±ëœ ë‹µë³€ì´ í•´ë‹¹ ì•½ê´€ ë‚´ìš©ì„ í¬í•¨í•˜ëŠ”ì§€ ê²€ì¦
   - Retry ë¡œì§: Validation ì‹¤íŒ¨ ì‹œ ìµœëŒ€ 3íšŒ ì¬ì‹œë„

3. **`format_rag_style(instruction, input_text, output)`**
   - RAG ìŠ¤íƒ€ì¼ í¬ë§·ìœ¼ë¡œ ë³€í™˜
   - EOS í† í° (`<|end_of_text|>`) ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€

**ì£¼ìš” ê°œì„  ì‚¬í•­:**
- Contextë¥¼ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í•˜ì—¬ "ë¬¸ì„œë¥¼ ë³´ê³  ë‹µë³€í•˜ëŠ”" íŒ¨í„´ í•™ìŠµ
- EOS í† í°ì„ ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€í•˜ì—¬ ì¢…ë£Œ íŒ¨í„´ í•™ìŠµ
- Validation ë¡œì§ìœ¼ë¡œ ë°ì´í„° í’ˆì§ˆ ë³´ì¥

### 5.3 íŒŒì¸íŠœë‹ - Phase 1 (`train_qlora.py`)

**ì£¼ìš” í•¨ìˆ˜:**

1. **`load_model_and_tokenizer()`**
   - Base Model 4-bit ë¡œë“œ
   - `prepare_model_for_kbit_training()` í˜¸ì¶œ (k-bit í•™ìŠµ ì¤€ë¹„)

2. **`setup_lora(model)`**
   - LoRA ì„¤ì • ì ìš©
   - `get_peft_model()` í˜¸ì¶œ
   - Trainable parameters ì¶œë ¥

3. **`train()`**
   - SFTTrainer ìƒì„± ë° í•™ìŠµ ì‹¤í–‰
   - ëª¨ë¸ ì €ì¥

### 5.4 íŒŒì¸íŠœë‹ - Phase 2 (`train_qlora_v2.py`) - ìµœì¢… ì±„íƒ

**ì£¼ìš” í•¨ìˆ˜:**

1. **`load_model_and_tokenizer()`**
   - Base Model 4-bit ë¡œë“œ
   - **EOS í† í° ì²˜ë¦¬ ê°œì„ :** `pad_token`ê³¼ `eos_token` ë¶„ë¦¬
   - `prepare_model_for_kbit_training()` í˜¸ì¶œ

2. **`setup_lora(model)`**
   - LoRA ì„¤ì • ì ìš© (Phase 1ê³¼ ë™ì¼)
   - `get_peft_model()` í˜¸ì¶œ

3. **`load_training_dataset()`**
   - RAG ìŠ¤íƒ€ì¼ ë°ì´í„°ì…‹ ë¡œë“œ (`train_dataset_rag.json`)
   - ìƒ˜í”Œ ë°ì´í„° í™•ì¸

4. **`train()`**
   - SFTTrainer ìƒì„± ë° í•™ìŠµ ì‹¤í–‰
   - **Formatting Function:** RAG ìŠ¤íƒ€ì¼ ë°ì´í„° ì²˜ë¦¬
   - ëª¨ë¸ ì €ì¥

**ì£¼ìš” ê°œì„  ì‚¬í•­:**
- EOS í† í° ì²˜ë¦¬ ê°•í™” (`pad_token`ê³¼ `eos_token` ë¶„ë¦¬)
- RAG ìŠ¤íƒ€ì¼ ë°ì´í„°ì…‹ ì§€ì›
- SFTTrainerì˜ `formatting_func` ì‚¬ìš©

### 5.5 í‰ê°€ - Phase 1 (`evaluate_final.py`)

**ì£¼ìš” í•¨ìˆ˜:**

1. **`load_base_model()`**
   - Base Model ë¡œë“œ (4-bit)

2. **`load_finetuned_model()`**
   - Base Model + LoRA Adapter ë¡œë“œ
   - `merge_and_unload()` í˜¸ì¶œ (ì–´ëŒ‘í„° ë³‘í•©)

3. **`evaluate_model(pipe, retriever, queries)`**
   - RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
   - ê²°ê³¼ ìˆ˜ì§‘

### 5.6 í‰ê°€ - Phase 2 (`evaluate_v2.py`) - ìµœì¢… ì±„íƒ

**ì£¼ìš” í•¨ìˆ˜:**

1. **`load_base_model()`**
   - Base Model ë¡œë“œ (4-bit)

2. **`load_finetuned_model(lora_path: str, model_name: str)`**
   - Base Model + LoRA Adapter ë¡œë“œ (v1 ë˜ëŠ” v2)
   - `merge_and_unload()` í˜¸ì¶œ

3. **`evaluate_model(pipe, retriever, queries, model_name: str)`**
   - RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
   - ì§„í–‰ë¥  í‘œì‹œ (Processing X/Y)
   - ê²°ê³¼ ìˆ˜ì§‘

**ì£¼ìš” ê°œì„  ì‚¬í•­:**
- ì„¸ ëª¨ë¸(Base, v1, v2) ë¹„êµ í‰ê°€ ì§€ì›
- ì§„í–‰ë¥  í‘œì‹œë¡œ í‰ê°€ ìƒíƒœ ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: ê° ëª¨ë¸ í‰ê°€ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬

---

## 6. ë©”ëª¨ë¦¬ ë° ì„±ëŠ¥

### 6.1 ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

- **Base Model (4-bit):** ì•½ 5-6GB VRAM
- **LoRA Adapters:** ì•½ 50-100MB (ì¶”ê°€)
- **í•™ìŠµ ì¤‘:** ì•½ 6-7GB VRAM (Gradient í¬í•¨)
- **ì´ í•„ìš” VRAM:** ì•½ 8GB (ì•ˆì „ ë§ˆì§„ í¬í•¨)

### 6.2 ì˜ˆìƒ í•™ìŠµ ì‹œê°„

- **ë°ì´í„°ì…‹:** 500ê°œ ìƒ˜í”Œ
- **Batch Size:** 8 (effective)
- **Max Steps:** 200
- **ì˜ˆìƒ ì‹œê°„:** ì•½ 30-60ë¶„ (GPU ì„±ëŠ¥ì— ë”°ë¼ ë‹¤ë¦„)

### 6.3 Inference ì„±ëŠ¥

- **Base Model:** ì•½ 3-5ì´ˆ/ë‹µë³€
- **Fine-tuned Model:** ì•½ 3-5ì´ˆ/ë‹µë³€ (ë™ì¼, LoRA ë³‘í•© í›„)

---

## 7. íŒŒì¼ êµ¬ì¡°

```
05_FineTuning/
â”œâ”€â”€ generate_data.py              # Phase 1: ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (ë‹¨ìˆœ QA)
â”œâ”€â”€ generate_data_v2.py           # Phase 2: RAG ìŠ¤íƒ€ì¼ ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (ìµœì¢…)
â”œâ”€â”€ train_qlora.py                # Phase 1: íŒŒì¸íŠœë‹ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ train_qlora_v2.py             # Phase 2: ì¬í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (ìµœì¢…)
â”œâ”€â”€ evaluate_final.py             # Phase 1: í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ (Base vs v1)
â”œâ”€â”€ evaluate_v2.py                # Phase 2: í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ (Base vs v1 vs v2, ìµœì¢…)
â”œâ”€â”€ train_dataset.json            # Phase 1: ìƒì„±ëœ í•™ìŠµ ë°ì´í„° (491ê°œ)
â”œâ”€â”€ train_dataset_rag.json        # Phase 2: RAG ìŠ¤íƒ€ì¼ í•™ìŠµ ë°ì´í„° (478ê°œ, ìµœì¢…)
â”œâ”€â”€ comparison_results.json        # Phase 1: í‰ê°€ ê²°ê³¼
â”œâ”€â”€ comparison_results_v2.json     # Phase 2: ì„¸ ëª¨ë¸ ë¹„êµ í‰ê°€ ê²°ê³¼ (ìµœì¢…)
â”œâ”€â”€ llama-3-ko-insurance-lora/    # Phase 1: ì €ì¥ëœ LoRA ì–´ëŒ‘í„° (v1)
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ adapter_model.safetensors
â”‚   â””â”€â”€ tokenizer files
â”œâ”€â”€ llama-3-ko-insurance-lora-v2/ # Phase 2: ì €ì¥ëœ LoRA ì–´ëŒ‘í„° (v2, ìµœì¢…)
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ adapter_model.safetensors
â”‚   â””â”€â”€ tokenizer files
â”œâ”€â”€ README_FineTuning_Log.md      # ì‘ì—… ë¡œê·¸
â””â”€â”€ SPEC_FineTuning_Strategy.md   # ê¸°ìˆ  ëª…ì„¸ì„œ (ë³¸ ë¬¸ì„œ)
```

---

## 8. ì˜ì¡´ì„±

### 8.1 í•„ìˆ˜ íŒ¨í‚¤ì§€

```python
torch
transformers
bitsandbytes      # 4-bit ì–‘ìí™”
peft              # LoRA êµ¬í˜„
accelerate        # ë¶„ì‚° í•™ìŠµ ì§€ì›
trl               # SFTTrainer
datasets          # ë°ì´í„°ì…‹ ë¡œë“œ
```

### 8.2 ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **GPU:** NVIDIA GPU with CUDA support (ìµœì†Œ 8GB VRAM)
- **Python:** 3.8+
- **CUDA:** 11.8+ (bitsandbytes í˜¸í™˜ì„±)

---

## 9. ì°¸ê³  ìë£Œ

- **QLoRA Paper:** Dettmers et al., "QLoRA: Efficient Finetuning of Quantized LLMs" (2023)
- **LoRA Paper:** Hu et al., "LoRA: Low-Rank Adaptation of Large Language Models" (2021)
- **Base Model:** beomi/Llama-3-Open-Ko-8B (HuggingFace)

---

---

## 10. Phase 2 ê°œì„  ì‚¬í•­ ìš”ì•½

### 10.1 ë°ì´í„°ì…‹ ê°œì„ 

**ë³€ê²½ ì‚¬í•­:**
- **AS-IS (Phase 1):** ë‹¨ìˆœ QA ìŒ (ì§ˆë¬¸ â†’ ë‹µë³€)
- **TO-BE (Phase 2):** RAG ìŠ¤íƒ€ì¼ (ì§€ì‹œ + ì•½ê´€ Context + ì§ˆë¬¸ â†’ ì•½ê´€ ê¸°ë°˜ ë‹µë³€)

**íš¨ê³¼:**
- ëª¨ë¸ì´ "ë¬¸ì„œë¥¼ ë³´ê³  ë‹µë³€í•˜ëŠ”" íŒ¨í„´ í•™ìŠµ
- í™˜ê° ë°œìƒë¥  ê°ì†Œ (55% â†’ 35%)
- Instruction Following ëŠ¥ë ¥ í–¥ìƒ

### 10.2 í•™ìŠµ ê°œì„ 

**ë³€ê²½ ì‚¬í•­:**
- EOS í† í° ì²˜ë¦¬ ê°•í™” (`pad_token`ê³¼ `eos_token` ë¶„ë¦¬)
- RAG ìŠ¤íƒ€ì¼ ë°ì´í„°ì…‹ ì§€ì›

**íš¨ê³¼:**
- ë°˜ë³µ ìƒì„± ë¬¸ì œ ì™„í™”
- ë‹µë³€ ì¢…ë£Œ íŒ¨í„´ í•™ìŠµ ê°œì„ 

### 10.3 í‰ê°€ ê°œì„ 

**ë³€ê²½ ì‚¬í•­:**
- ì„¸ ëª¨ë¸(Base, v1, v2) ë¹„êµ í‰ê°€
- ì§„í–‰ë¥  í‘œì‹œ ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ 

**íš¨ê³¼:**
- ì²´ê³„ì ì¸ ì„±ëŠ¥ ë¹„êµ ë¶„ì„ ê°€ëŠ¥
- ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ëª…í™•í•œ ì‹ë³„

---

## 11. ì¶”ë¡  íŒŒë¼ë¯¸í„° ìµœì í™” (Phase 3)

### 11.1 ìµœì í™” ëª©ì 

ì¬í•™ìŠµ ì—†ì´ ì¶”ë¡ (Inference) ë‹¨ê³„ì—ì„œ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì—¬ ê¼¬ë¦¬í‘œ í™˜ê°(Tail Hallucination) ë¬¸ì œë¥¼ ì™„í™”.

### 11.2 ì ìš©ëœ íŒŒë¼ë¯¸í„°

**ë³€ê²½ ì‚¬í•­:**

1. **repetition_penalty: 1.0 â†’ 1.2**
   - ë°˜ë³µ ìƒì„± ë¬¸ì œ ì™„í™”
   - ë™ì¼ ë¬¸ì¥ ë°˜ë³µ ì–µì œ

2. **temperature: 0.7 â†’ 0.1**
   - ì‚¬ì‹¤ ê¸°ë°˜ ë‹µë³€ ê°•ì œ
   - ì°½ì˜ì„± ì–µì œë¡œ í™˜ê° ê°ì†Œ

3. **stop_sequences í›„ì²˜ë¦¬**
   - ê°ì§€ ë¬¸êµ¬: `["ì´ë²ˆì— ìƒˆë¡œ ë‚˜ì˜¨", "Este es", "Ich mÃ¶chte", "ì´ë²ˆì—”", "ì´ë²ˆì—"]`
   - ìƒì„± í›„ í™˜ê° ë¬¸êµ¬ê°€ í¬í•¨ëœ ê²½ìš° í•´ë‹¹ ë¶€ë¶„ ìë™ ì œê±°

### 11.3 êµ¬í˜„ ìƒì„¸

**íŒŒì¼:** `evaluate_v2.py`

**ì£¼ìš” ë³€ê²½ ì‚¬í•­:**

```python
def evaluate_model(pipe, retriever, queries: List[str], model_name: str):
    """ëª¨ë¸ í‰ê°€ ì‹¤í–‰ (ìµœì í™”ëœ íŒŒë¼ë¯¸í„° ì ìš©)"""
    results = []
    
    # í™˜ê° ë¬¸êµ¬ ê°ì§€ìš© stop sequences
    stop_phrases = ["ì´ë²ˆì— ìƒˆë¡œ ë‚˜ì˜¨", "Este es", "Ich mÃ¶chte", "ì´ë²ˆì—”", "ì´ë²ˆì—"]
    
    for i, query in enumerate(queries, 1):
        # ... (Retrieval ë° Context êµ¬ì„±) ...
        
        # Generation (ìµœì í™”ëœ íŒŒë¼ë¯¸í„° ì ìš©)
        output = pipe(
            prompt,
            repetition_penalty=1.2,  # ë°˜ë³µ ìƒì„± ì–µì œ
            temperature=0.1,  # ì‚¬ì‹¤ ê¸°ë°˜ ë‹µë³€ ê°•ì œ
            max_new_tokens=256,
            do_sample=True,
            top_p=0.9
        )
        answer = output[0]['generated_text'].strip()
        
        # Stop sequences í›„ì²˜ë¦¬
        for phrase in stop_phrases:
            if phrase in answer:
                idx = answer.find(phrase)
                answer = answer[:idx].strip()
                break
        
        results.append({...})
    
    return results
```

### 11.4 ì„±ëŠ¥ ê°œì„  ê²°ê³¼

**ìµœì í™” ì „í›„ í™˜ê° ë°œìƒë¥  ë¹„êµ:**

| ëª¨ë¸ | ìµœì í™” ì „ | ìµœì í™” í›„ | ê°œì„ ìœ¨ |
| :--- | :---: | :---: | :---: |
| **Base Model** | 30.0% | 10.0% | 20.0%p ê°ì†Œ |
| **Fine-tuned v1** | 55.0% | 15.0% | 40.0%p ê°ì†Œ |
| **Fine-tuned v2** | 35.0% | 25.0% | 10.0%p ê°ì†Œ |

**ì£¼ìš” ë°œê²¬:**
- Base ëª¨ë¸ê³¼ v1 ëª¨ë¸ì—ì„œ í° í­ì˜ ê°œì„  í™•ì¸
- v2 ëª¨ë¸ì—ì„œë„ 10.0%p ê°œì„  í™•ì¸
- ì¬í•™ìŠµ ì—†ì´ ì¶”ë¡  íŒŒë¼ë¯¸í„°ë§Œ ì¡°ì •í•˜ì—¬ ì„±ëŠ¥ ê°œì„  ë‹¬ì„±

### 11.5 í•œê³„ ë° í–¥í›„ ê°œì„ 

**í•œê³„:**
- v2 ëª¨ë¸ì˜ í™˜ê°ë¥ ì´ ì—¬ì „íˆ 25%ë¡œ ë†’ì€ ìˆ˜ì¤€
- Stop sequences í›„ì²˜ë¦¬ëŠ” ëª¨ë“  í™˜ê° íŒ¨í„´ì„ ê°ì§€í•˜ì§€ ëª»í•¨

**í–¥í›„ ê°œì„  ë°©ì•ˆ:**
1. Stop sequences ë¦¬ìŠ¤íŠ¸ í™•ì¥
2. `repetition_penalty` ì¶”ê°€ ì¡°ì • (1.3~1.5)
3. í•™ìŠµ ë°ì´í„°ì—ì„œ í™˜ê° íŒ¨í„´ì„ ìˆ˜ë™ìœ¼ë¡œ í•„í„°ë§

---

## 12. ë³‘ë ¬ ë°ì´í„° ìƒì„± ì „ëµ (Parallel Data Generation Strategy)

### 12.1 ê°œìš”

ëŒ€ê·œëª¨ QA ë°ì´í„°ì…‹ ìƒì„±ì„ ìœ„í•´ ì—¬ëŸ¬ API í‚¤ë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ì²˜ë¦¬ ë°©ì‹ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ê° ì›Œì»¤ê°€ ë…ë¦½ì ìœ¼ë¡œ ì²­í¬ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì „ì²´ ì²˜ë¦¬ ì‹œê°„ì„ ë‹¨ì¶•í•˜ê³ , Rate Limitì„ ë¶„ì‚°ì‹œí‚µë‹ˆë‹¤.

### 12.2 ì•„í‚¤í…ì²˜

```
ì „ì²´ ì²­í¬ ë°ì´í„° (chunked_data.jsonl)
    â†“
[Sharding] ì „ì²´ ì²­í¬ë¥¼ ì›Œì»¤ ìˆ˜ë¡œ ê· ë“± ë¶„í• 
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker 2  â”‚  Worker 3  â”‚  ...  â”‚  Worker 8  â”‚
â”‚  API Key 2 â”‚  API Key 3 â”‚  ...  â”‚  API Key 8 â”‚
â”‚  ì²­í¬ 268ê°œ â”‚  ì²­í¬ 239ê°œ â”‚  ...  â”‚  ì²­í¬ 255ê°œ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
ê° ì›Œì»¤ê°€ ë…ë¦½ì ìœ¼ë¡œ QA ìŒ ìƒì„±
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ dataset_part_2.json â”‚ dataset_part_3.json â”‚ ... â”‚ dataset_part_8.json â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
[í†µí•©] ëª¨ë“  íŒŒì¼ì„ í•˜ë‚˜ë¡œ í†µí•©
```

### 12.3 ë°ì´í„° ë¶„í•  ì „ëµ (Sharding Strategy)

**ë¶„í•  ë°©ì‹:**
```python
total_chunks = len(all_chunks)
chunk_size = math.ceil(total_chunks / args.total_keys)
start_idx = (args.key_num - 1) * chunk_size
end_idx = min(start_idx + chunk_size, total_chunks)
my_chunks = all_chunks[start_idx:end_idx]
```

**íŠ¹ì§•:**
- ì „ì²´ ì²­í¬ë¥¼ ì›Œì»¤ ìˆ˜ë¡œ ê· ë“± ë¶„í• 
- ê° ì›Œì»¤ê°€ ë…ë¦½ì ìœ¼ë¡œ í• ë‹¹ëœ ì²­í¬ë§Œ ì²˜ë¦¬
- ì¤‘ë³µ ì²˜ë¦¬ ì—†ìŒ

### 12.4 Rate Limit ëŒ€ì‘ ì „ëµ

#### 12.4.1 ì¬ì‹œë„ ë¡œì§

```python
def call_gemini_api_robust(api_key, payload, max_retries=5):
    base_delay = 2.0
    
    for attempt in range(max_retries + 1):
        response = requests.post(...)
        
        if response.status_code == 429:  # Rate Limit
            wait_time = min(base_delay * (2 ** attempt) * 2 + random.uniform(1, 3), 30)
            if attempt < max_retries:
                time.sleep(wait_time)
                continue
```

**íŠ¹ì§•:**
- ì§€ìˆ˜ ë°±ì˜¤í”„: `base_delay * (2 ** attempt) * 2`
- ëœë¤ ì§€ì—°: `random.uniform(1, 3)` ì¶”ê°€
- ìµœëŒ€ ëŒ€ê¸° ì‹œê°„: 30ì´ˆë¡œ ì œí•œ
- ìµœëŒ€ ì¬ì‹œë„: 5íšŒ

#### 12.4.2 ìš”ì²­ ê°„ ê°„ê²©

```python
# Rate Limit íšŒí”¼ë¥¼ ìœ„í•œ ìš”ì²­ ê°„ ê°„ê²© ì¶”ê°€ (0.2ì´ˆë¡œ ë‹¨ì¶•)
time.sleep(0.2)
```

**íŠ¹ì§•:**
- ê° API í˜¸ì¶œ ì‚¬ì´ì— 0.2ì´ˆ ê°„ê²© ì¶”ê°€
- Rate Limit íšŒí”¼ë¥¼ ìœ„í•œ ì˜ˆë°©ì  ì¡°ì¹˜

### 12.5 ë°ì´í„° ì €ì¥ ì „ëµ

#### 12.5.1 ì£¼ê¸°ì  ì €ì¥

```python
# 10ê°œ ì²­í¬ë§ˆë‹¤ íŒŒì¼ ì €ì¥ (ë°ì´í„° ì†ì‹¤ ë°©ì§€)
if (i + 1) % 10 == 0:
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)
```

**íŠ¹ì§•:**
- 10ê°œ ì²­í¬ë§ˆë‹¤ íŒŒì¼ ì €ì¥
- ë°ì´í„° ì†ì‹¤ ë°©ì§€
- ì¤‘ë‹¨ ì‹œ Resume ê°€ëŠ¥

#### 12.5.2 Resume ê¸°ëŠ¥

```python
if os.path.exists(output_file):
    with open(output_file, 'r', encoding='utf-8') as f:
        dataset = json.load(f)
        # ì´ë¯¸ ì²˜ë¦¬ëœ chunk_id ìˆ˜ì§‘
        for item in dataset:
            if 'chunk_id' in item:
                processed_chunk_ids.add(item['chunk_id'])
```

**íŠ¹ì§•:**
- ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ
- ì´ë¯¸ ì²˜ë¦¬ëœ ì²­í¬ëŠ” ê±´ë„ˆëœ€
- ì¤‘ë‹¨ í›„ ì¬ì‹œì‘ ì‹œ ì´ì–´ì„œ ì§„í–‰ ê°€ëŠ¥

### 12.6 ì„±ëŠ¥ ìµœì í™”

#### 12.6.1 ì†ë„ ê°œì„  ê²°ê³¼

| êµ¬ë¶„ | ìµœì´ˆ ì†ë„ | ìµœì í™” í›„ | ê°œì„ ìœ¨ |
| :--- | :---: | :---: | :---: |
| ë‹¨ì¼ ì²­í¬ ì²˜ë¦¬ ì‹œê°„ | 387ì´ˆ/ì²­í¬ | 284.95ì´ˆ/ì²­í¬ | **26.3% ê°œì„ ** |

**ìµœì í™” ë°©ë²•:**
1. ëŒ€ê¸° ì‹œê°„ ë‹¨ì¶•: ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ì„ 30ì´ˆë¡œ ì œí•œ
2. ìš”ì²­ ê°„ ê°„ê²© ìµœì†Œí™”: 0.2ì´ˆë¡œ ë‹¨ì¶•
3. ë³‘ë ¬ ì²˜ë¦¬: 7ê°œ ì›Œì»¤ë¡œ ë™ì‹œ ì²˜ë¦¬

#### 12.6.2 Rate Limit ì—ëŸ¬ ëŒ€ì‘

**í˜„í™©:**
- ì´ Rate Limit ì—ëŸ¬: 933íšŒ
- ê° ì›Œì»¤ë‹¹ í‰ê· : ì•½ 133-134íšŒ
- ì¬ì‹œë„ ì„±ê³µë¥ : ì¬ì‹œë„ ë¡œì§ ì‘ë™í•˜ì—¬ ê³„ì† ì§„í–‰ ì¤‘

**ëŒ€ì‘ ì „ëµ:**
1. ì§€ìˆ˜ ë°±ì˜¤í”„ + ëœë¤ ì§€ì—°
2. ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ ì œí•œ (30ì´ˆ)
3. ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì œí•œ (5íšŒ)

### 12.7 ì‹¤í–‰ ë°©ë²•

#### 12.7.1 ë‹¨ì¼ ì›Œì»¤ ì‹¤í–‰

```bash
python generate_data_parallel.py \
    --key_num 2 \
    --total_keys 8 \
    --output_dir generated_data_v2
```

#### 12.7.2 ë³‘ë ¬ ì‹¤í–‰ (7ê°œ ì›Œì»¤)

```bash
# run_parallel.sh ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
bash run_parallel.sh
```

**ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©:**
```bash
for i in {2..8}; do
    python generate_data_parallel.py \
        --key_num $i \
        --total_keys 8 \
        --output_dir generated_data_v2 &
done
wait
```

### 12.8 í•œê³„ ë° í–¥í›„ ê°œì„ 

**í•œê³„:**
1. Rate Limit ì—ëŸ¬ê°€ ì—¬ì „íˆ ë¹ˆë²ˆí•˜ê²Œ ë°œìƒ (933íšŒ)
2. ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ì´ ì—¬ì „íˆ ê¹€ (ì•½ 14-15ì‹œê°„)
3. API í‚¤ë³„ Rate Limit ì œí•œìœ¼ë¡œ ì¸í•œ ë³‘ëª©

**í–¥í›„ ê°œì„  ë°©ì•ˆ:**
1. ì›Œì»¤ ìˆ˜ë¥¼ ëŠ˜ë ¤ ì¶”ê°€ ì†ë„ ê°œì„  (API í‚¤ ì¶”ê°€ í•„ìš”)
2. Rate Limit ì—ëŸ¬ë¥¼ ë” íš¨ê³¼ì ìœ¼ë¡œ íšŒí”¼í•˜ê¸° ìœ„í•œ ìš”ì²­ ê°„ê²© ì¡°ì •
3. API í‚¤ í’€ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•ìœ¼ë¡œ Rate Limit ë¶„ì‚° ìµœì í™”
4. ë™ì  ì›Œì»¤ ìˆ˜ ì¡°ì •ìœ¼ë¡œ Rate Limit ìƒí™©ì— ë”°ë¼ ìë™ ì¡°ì ˆ

---

**ìµœì¢… ì—…ë°ì´íŠ¸:** 2025-11-24 00:50 (KST)

### 11.7 ë°ì´í„°ì…‹ í’ˆì§ˆ ê²€ì¦ ë° í†µí•© (Dataset Validation) - 2025-11-24 01:20

#### 11.7.1 ê²€ì¦ ê°œìš”
*   **ëª©ì :** ë³‘ë ¬ ìƒì„±ëœ 7ê°œ íŒŒì¼(`generated_data_v2/*.json`)ì„ í•˜ë‚˜ë¡œ í†µí•©í•˜ê³ , ë¶ˆëŸ‰ ë°ì´í„°ë¥¼ ì œê±°í•˜ì—¬ í•™ìŠµìš© ë°ì´í„°ì…‹ êµ¬ì¶•.
*   **ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸:** `validate_and_merge.py`

#### 11.7.2 ê²€ì¦ ê¸°ì¤€ (Criteria)
1.  **í•„ìˆ˜ í•„ë“œ ì²´í¬:** `instruction`, `output` ëˆ„ë½ ì—¬ë¶€ í™•ì¸.
2.  **ì¤‘ë³µ ì œê±°:** ë™ì¼í•œ ì§ˆë¬¸(Instruction) ì œê±°.
3.  **í’ˆì§ˆ í•„í„°ë§:**
    *   **ê¸¸ì´:** ë‹µë³€ ê¸¸ì´ 10ì ë¯¸ë§Œ ì œê±°.
    *   **ì™„ê²°ì„±:** ë¬¸ì¥ ë¶€í˜¸(., ?, !, ë‹¤, ìš”, ì£ )ë¡œ ëë‚˜ì§€ ì•ŠëŠ” ì˜ë¦° ë¬¸ì¥ ì œê±°.
    *   **ë¬´ì˜ë¯¸í•œ ë‹µë³€:** "ëª…ì‹œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤" ë“± í™˜ê°ì„± íšŒí”¼ ë‹µë³€ ì œê±°.

#### 11.7.3 ê²€ì¦ ê²°ê³¼ (Validation Results)
*   **ì´ ìƒì„± ë°ì´í„°:** 6,688ê°œ
*   **ìµœì¢… ìœ íš¨ ë°ì´í„°:** **5,434ê°œ** (í†µê³¼ìœ¨ 81.3%)
*   **í•„í„°ë§ ë‚´ì—­:**
    *   ì¤‘ë³µ ì œê±°: 9ê°œ
    *   ë„ˆë¬´ ì§§ì€ ë‹µë³€: 310ê°œ
    *   ë¶ˆì™„ì „(ì˜ë¦¼): 783ê°œ
    *   ë¬´ì˜ë¯¸í•œ ë‹µë³€: 152ê°œ
*   **ìœ í˜•ë³„ ë¶„í¬:**
    *   Fact: 1,617ê°œ (29.8%)
    *   Scenario: 1,555ê°œ (28.6%)
    *   Easy: 2,262ê°œ (41.6%)

#### 11.7.4 ê²°ë¡ 
*   **5,434ê°œ**ì˜ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ì´ `train_dataset_final_v2.json`ìœ¼ë¡œ í†µí•©ë¨.
*   ìœ í˜•ë³„ ë¶„í¬ê°€ ê· í˜•ì ì´ë©°, ë¶ˆëŸ‰ ë°ì´í„°ê°€ íš¨ê³¼ì ìœ¼ë¡œ ì œê±°ë¨.
*   **Next Step:** í•´ë‹¹ ë°ì´í„°ì…‹ìœ¼ë¡œ QLoRA íŒŒì¸íŠœë‹ ì‹œì‘.

---

**ìµœì¢… ì—…ë°ì´íŠ¸:** 2025-11-24 01:30 (KST)

## 13. Phase 3: ëŒ€ê·œëª¨ íŒŒì¸íŠœë‹ ì „ëµ (Scale-Up Fine-Tuning)

### 13.1 í•™ìŠµ ëª©í‘œ
*   í™•ë³´ëœ 5,434ê°œì˜ ê³ í’ˆì§ˆ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ì˜ ë„ë©”ì¸ ì§€ì‹ ë° ë‹µë³€ ìŠ¤íƒ€ì¼ì„ ì™„ì„±.
*   "ì§€ì‹ ì•”ê¸°"ê°€ ì•„ë‹Œ "ì£¼ì–´ì§„ ë¬¸ë§¥(ì•½ê´€)ì„ ë³´ê³  ë‹µí•˜ëŠ” ëŠ¥ë ¥" ê·¹ëŒ€í™”.

### 13.2 ë°ì´í„°ì…‹ ìŠ¤í™
*   **íŒŒì¼:** `train_dataset_final_v2.json` (5,434 samples)
*   **í¬ë§·:** Instruction Tuning Format
    ### ì§€ì‹œ
    {instruction}

    ### ì…ë ¥
    {input} (ì•½ê´€ ë‚´ìš©)

    ### ì¶œë ¥
    {output}
    ### 13.3 í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • (Hyperparameters)

| íŒŒë¼ë¯¸í„° | ì„¤ì •ê°’ | ê·¼ê±° |
| :--- | :--- | :--- |
| **Model** | `beomi/Llama-3-Open-Ko-8B` | í•œêµ­ì–´ ë² ì´ìŠ¤ ëª¨ë¸ í‘œì¤€ |
| **Method** | **QLoRA** (4-bit + LoRA) | ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë° ì„±ëŠ¥ ë°¸ëŸ°ìŠ¤ |
| **Epochs** | **3** | ë°ì´í„° 5.4kê°œ ê¸°ì¤€, 3 epochë©´ ì¶©ë¶„íˆ ìˆ˜ë ´ ì˜ˆìƒ (ê³¼ì í•© ë°©ì§€) |
| **Batch Size** | **4** (per device) | 24GB VRAM ê¸°ì¤€ OOM ë°©ì§€ (Gradient Accumulation 4ë¡œ ì„¤ì • ì‹œ ì‹¤ì œ ë°°ì¹˜ 16) |
| **Learning Rate** | **2e-4** | QLoRA í‘œì¤€ í•™ìŠµë¥  |
| **LoRA Rank** | **16** | íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„±ê³¼ í‘œí˜„ë ¥ì˜ ê· í˜•ì  |
| **LoRA Alpha** | **32** | ì¼ë°˜ì ìœ¼ë¡œ Rankì˜ 2ë°° ì„¤ì • |
| **Max Length** | **2048** | ì•½ê´€(Context) + ì§ˆë¬¸ + ë‹µë³€ì„ ëª¨ë‘ í¬í•¨í•˜ê¸° ìœ„í•œ ì¶©ë¶„í•œ ê¸¸ì´ |
| **Warmup Ratio** | **0.03** | ì´ˆê¸° í•™ìŠµ ì•ˆì •í™” |

### 13.4 í•™ìŠµ í™˜ê²½
*   **GPU:** NVIDIA A100 / L4 (24GB VRAM ì´ìƒ ê¶Œì¥)
*   **Library:** `transformers`, `peft`, `bitsandbytes`, `trl`

---

**ìµœì¢… ì—…ë°ì´íŠ¸:** 2025-11-24 01:30 (KST)

