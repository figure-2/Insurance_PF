import json
import os
from collections import defaultdict

# ì„¤ì •
INPUT_FILE = "/home/pencilfoxs/0_Insurance_PF/05_FineTuning/train_dataset_v4_negative_enhanced.json"
OUTPUT_FILE = "/home/pencilfoxs/0_Insurance_PF/05_FineTuning/train_dataset_v4_clean.json"

def validate_and_clean():
    print(f"ğŸ” ë°ì´í„° ê²€ì¦ ì‹œì‘: {INPUT_FILE}")
    
    if not os.path.exists(INPUT_FILE):
        print("âŒ ì…ë ¥ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    try:
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except json.JSONDecodeError as e:
        print(f"âŒ JSON ë¬¸ë²• ì˜¤ë¥˜ ë°œìƒ: {e}")
        # íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ê²½ìš° ë³µêµ¬ ë¡œì§ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ (ì—¬ê¸°ì„  ìƒëµ)
        return

    print(f"ğŸ“¥ ë¡œë“œëœ ë°ì´í„°: {len(data)}ê°œ")
    
    cleaned_data = []
    seen_hashes = set()
    stats = defaultdict(int)
    
    for item in data:
        # 1. í•„ìˆ˜ í•„ë“œ ì²´í¬
        if not all(k in item for k in ['instruction', 'input', 'output', 'type']):
            stats['missing_fields'] += 1
            continue
            
        # 2. ë‚´ìš© ìœ íš¨ì„± ì²´í¬ (ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš°)
        if len(item['output'].strip()) < 5:
            stats['too_short'] += 1
            continue
            
        # 3. ì¤‘ë³µ ì œê±° (Instruction + Input ê¸°ì¤€)
        # ë„ì–´ì“°ê¸° ë¬´ì‹œí•˜ê³  ë¹„êµ
        content_hash = hash((item['instruction'].replace(" ", ""), item['input'].replace(" ", "")))
        if content_hash in seen_hashes:
            stats['duplicate'] += 1
            continue
        
        seen_hashes.add(content_hash)
        
        # 4. Type ì •ê·œí™” (í˜¹ì‹œ ëª¨ë¥¼ ì˜¤íƒ€ ë°©ì§€)
        q_type = item['type'].lower().strip()
        item['type'] = q_type
        
        cleaned_data.append(item)
        stats[f'type_{q_type}'] += 1

    # ì €ì¥
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(cleaned_data, f, ensure_ascii=False, indent=2)

    print("\n" + "="*50)
    print("ğŸ“Š ê²€ì¦ ê²°ê³¼ ë¦¬í¬íŠ¸")
    print("="*50)
    print(f"âœ… ìœ íš¨ ë°ì´í„°: {len(cleaned_data)}ê°œ (ì €ì¥ë¨: {OUTPUT_FILE})")
    print(f"ğŸ—‘ï¸ ì œê±°ëœ ë°ì´í„°:")
    print(f"   - ì¤‘ë³µ: {stats['duplicate']}ê°œ")
    print(f"   - í•„ë“œ ëˆ„ë½: {stats['missing_fields']}ê°œ")
    print(f"   - ë‚´ìš© ë¶€ì‹¤: {stats['too_short']}ê°œ")
    print("\nğŸ“ˆ ìœ í˜•ë³„ ë¶„í¬ (Cleaned):")
    for k, v in stats.items():
        if k.startswith('type_'):
            print(f"   - {k.replace('type_', '').upper()}: {v}ê°œ")
    print("="*50)

if __name__ == "__main__":
    validate_and_clean()
