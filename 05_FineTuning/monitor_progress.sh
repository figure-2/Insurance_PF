#!/bin/bash

# ë°ì´í„° ìƒì„± ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸

WORK_DIR="/home/pencilfoxs/0_Insurance_PF/05_FineTuning"
cd "$WORK_DIR" || exit 1

clear
echo "=========================================="
echo "ğŸ“Š ë°ì´í„° ìƒì„± ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§"
echo "=========================================="
echo "â° í˜„ì¬ ì‹œê°„: $(date '+%Y-%m-%d %H:%M:%S')"
echo ""

# 1. ì‹¤í–‰ ì¤‘ì¸ ì›Œì»¤ í™•ì¸
echo "=== ğŸ”„ ì‹¤í–‰ ì¤‘ì¸ ì›Œì»¤ ==="
worker_count=$(ps aux | grep "generate_data_parallel" | grep -v grep | wc -l)
if [ $worker_count -eq 0 ]; then
    echo "  âš ï¸  ì‹¤í–‰ ì¤‘ì¸ ì›Œì»¤ê°€ ì—†ìŠµë‹ˆë‹¤!"
else
    echo "  âœ… ì´ $worker_count ê°œ ì›Œì»¤ ì‹¤í–‰ ì¤‘"
    ps aux | grep "generate_data_parallel" | grep -v grep | awk '{printf "    Worker PID: %s | CPU: %s%% | MEM: %s%% | ì‹¤í–‰ì‹œê°„: %s\n", $2, $3, $4, $10}'
fi
echo ""

# 2. ê° ì›Œì»¤ë³„ ì§„í–‰ ìƒí™©
echo "=== ğŸ“ˆ ê° ì›Œì»¤ë³„ ì§„í–‰ ìƒí™© ==="
total_processed=0
for i in {2..8}; do
    if [ -f "logs/worker_$i.log" ]; then
        # ì§„í–‰ë¥  ì¶”ì¶œ (ì˜ˆ: "3/801")
        progress=$(tail -1 "logs/worker_$i.log" 2>/dev/null | grep -oP '\d+/\d+' | head -1)
        if [ -n "$progress" ]; then
            current=$(echo $progress | cut -d'/' -f1)
            total=$(echo $progress | cut -d'/' -f2)
            if [ -n "$current" ] && [ -n "$total" ]; then
                percent=$(echo "scale=1; $current * 100 / $total" | bc 2>/dev/null || echo "0")
                echo "  Worker $i: $progress ($percent%)"
                total_processed=$((total_processed + current))
            fi
        fi
    fi
done
echo ""

# 3. ìƒì„±ëœ ë°ì´í„° íŒŒì¼
echo "=== ğŸ“ ìƒì„±ëœ ë°ì´í„° íŒŒì¼ ==="
if [ -d "generated_data_v2" ]; then
    file_count=$(find generated_data_v2 -name "dataset_part_*.json" -type f 2>/dev/null | wc -l)
    if [ $file_count -gt 0 ]; then
        echo "  âœ… $file_count ê°œ íŒŒì¼ ìƒì„±ë¨"
        total_samples=0
        for f in generated_data_v2/dataset_part_*.json; do
            if [ -f "$f" ]; then
                count=$(python3 -c "import json; f=open('$f'); data=json.load(f); print(len(data))" 2>/dev/null || echo "0")
                size=$(ls -lh "$f" | awk '{print $5}')
                echo "    $(basename $f): $count ê°œ ìƒ˜í”Œ ($size)"
                total_samples=$((total_samples + count))
            fi
        done
        echo "  ğŸ“Š ì´ ìƒì„±ëœ QA ìŒ: $total_samples ê°œ"
        estimated_chunks=$((total_samples / 3))
        total_chunks=6402
        if [ $total_chunks -gt 0 ]; then
            progress_pct=$(echo "scale=2; $estimated_chunks * 100 / $total_chunks" | bc 2>/dev/null || echo "0")
            echo "  ğŸ“ˆ ì˜ˆìƒ ì§„í–‰ë¥ : ì•½ ${progress_pct}% ($estimated_chunks / $total_chunks ì²­í¬)"
        fi
    else
        echo "  â³ ì•„ì§ íŒŒì¼ ìƒì„± ì „... (10ê°œ ì²­í¬ë§ˆë‹¤ ì €ì¥)"
    fi
else
    echo "  â³ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì•„ì§ ìƒì„± ì•ˆ ë¨"
fi
echo ""

# 4. ì—ëŸ¬ í™•ì¸
echo "=== âš ï¸  ì—ëŸ¬ í™•ì¸ ==="
error_found=0
for i in {2..8}; do
    if [ -f "logs/worker_$i.log" ]; then
        if grep -qi "error\|exception\|failed\|âŒ" "logs/worker_$i.log" 2>/dev/null; then
            echo "  âš ï¸  Worker $i ì—ëŸ¬ ë°œê²¬:"
            grep -i "error\|exception\|failed\|âŒ" "logs/worker_$i.log" 2>/dev/null | tail -2 | sed 's/^/    /'
            error_found=1
        fi
    fi
done
if [ $error_found -eq 0 ]; then
    echo "  âœ… ì—ëŸ¬ ì—†ìŒ"
fi
echo ""

# 5. ì˜ˆìƒ ì™„ë£Œ ì‹œê°„
echo "=== â±ï¸  ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ ==="
if [ $total_processed -gt 0 ]; then
    # í‰ê·  ì†ë„ ê³„ì‚° (ì´ˆë‹¹ ì²˜ë¦¬ ì²­í¬ ìˆ˜)
    # ê° ì›Œì»¤ê°€ ì•½ 25ì´ˆ/ì²­í¬ ì†Œìš” (ë¡œê·¸ì—ì„œ í™•ì¸)
    avg_time_per_chunk=25
    remaining_chunks=$((6402 - total_processed))
    total_seconds=$((remaining_chunks * avg_time_per_chunk / 7))  # 7ê°œ ì›Œì»¤ë¡œ ë³‘ë ¬ ì²˜ë¦¬
    hours=$((total_seconds / 3600))
    minutes=$(((total_seconds % 3600) / 60))
    echo "  ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: ì•½ ${hours}ì‹œê°„ ${minutes}ë¶„"
    echo "  (í˜„ì¬ ì†ë„ ê¸°ì¤€, ì‹¤ì œ ì†ë„ëŠ” ë³€ë™ ê°€ëŠ¥)"
fi
echo ""

echo "=========================================="
echo "ğŸ’¡ ëª¨ë‹ˆí„°ë§ ëª…ë ¹ì–´:"
echo "   tail -f $WORK_DIR/logs/worker_*.log"
echo "   ps aux | grep generate_data_parallel"
echo "=========================================="
