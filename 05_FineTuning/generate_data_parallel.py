import json
import random
import argparse
import os
import time
import requests
import math
from pathlib import Path
from tqdm import tqdm
from dotenv import load_dotenv

# -----------------------------------------------------------------------------
# 1. í™˜ê²½ ì„¤ì • ë° API í‚¤ ë¡œë“œ
# -----------------------------------------------------------------------------
def load_api_key(key_num):
    """
    .env2 íŒŒì¼ì—ì„œ ì§€ì •ëœ ë²ˆí˜¸ì˜ API í‚¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    ì˜ˆ: key_num=2 -> GOOGLE_API_KEY_2
    """
    env_paths = ['/home/pencilfoxs/00_new/.env2', '/home/pencilfoxs/PJ/.env2']
    
    # í™˜ê²½ ë³€ìˆ˜ ì´ë¦„ ê²°ì •
    target_key_name = f"GOOGLE_API_KEY_{key_num}" if key_num > 1 else "GOOGLE_API_KEY"
    
    # 1. os.environ í™•ì¸
    for path in env_paths:
        if os.path.exists(path):
            load_dotenv(path)
            
    api_key = os.getenv(target_key_name)
    
    # 2. íŒŒì¼ ì§ì ‘ íŒŒì‹± (fallback)
    if not api_key:
        for path in env_paths:
            if os.path.exists(path):
                with open(path, 'r', encoding='utf-8') as f:
                    for line in f:
                        # ì£¼ì„ ì œê±° ë° ê³µë°± ì œê±°
                        clean_line = line.split('#')[0].strip()
                        if clean_line.startswith(f"{target_key_name}="):
                            api_key = clean_line.split('=', 1)[1].strip()
                            break
            if api_key: break
            
    if not api_key:
        raise ValueError(f"API Key {target_key_name} not found in .env2 files.")
        
    return api_key

# ëª¨ë¸ëª… (fallback ì§€ì›)
GEMINI_MODEL = "gemini-2.5-flash"
GEMINI_API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent"

# -----------------------------------------------------------------------------
# 2. Multi-Persona Prompts (ë²¤ì¹˜ë§ˆí‚¹ ì ìš©)
# -----------------------------------------------------------------------------
PROMPT_FACT = """
ë‹¹ì‹ ì€ **'ì•½ê´€ì„ ê¼¼ê¼¼íˆ ë”°ì§€ëŠ” ê¹ê¹í•œ ë³´í—˜ ê°€ì…ì'**ì…ë‹ˆë‹¤.
ì œê³µëœ [ë³´í—˜ ì•½ê´€]ì„ ì½ê³ , ë³´ìƒ í•œë„, ë©´ì±… ê¸°ê°„, ì§€ê¸‰ ì¡°ê±´ ë“± **ì •í™•í•œ ì‚¬ì‹¤ì´ë‚˜ ìˆ˜ì¹˜**ë¥¼ í™•ì¸í•˜ëŠ” ë‚ ì¹´ë¡œìš´ ì§ˆë¬¸ì„ í•˜ë‚˜ë§Œ ë§Œë“œì„¸ìš”.

[ê·œì¹™]
1. ëª¨í˜¸í•œ ì§ˆë¬¸ ê¸ˆì§€. ì •í™•í•œ ìˆ«ìë‚˜ ì¡°ê±´ì„ ë¬¼ì–´ë³´ì„¸ìš”.
2. ì˜ˆ: "ì•” ì§„ë‹¨ë¹„ì˜ ê°ì•¡ ê¸°ê°„ì€ ê°€ì… í›„ ì •í™•íˆ ë©°ì¹ ì¸ê°€ìš”?"
3. ë°˜ë“œì‹œ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ë§Œë“œì„¸ìš”.

[ë³´í—˜ ì•½ê´€]
{text}

[ìƒì„± í˜•ì‹]
ì§ˆë¬¸: [ì§ˆë¬¸ë‚´ìš©]
ë‹µë³€: [ì•½ê´€ì— ê·¼ê±°í•œ ëª…í™•í•œ ë‹µë³€]
"""

PROMPT_SCENARIO = """
ë‹¹ì‹ ì€ **'ê°‘ì‘ìŠ¤ëŸ¬ìš´ ì‚¬ê³ ë¥¼ ë‹¹í•´ ë‹¹í™©í•œ í”¼í•´ì'**ì…ë‹ˆë‹¤.
ì œê³µëœ [ë³´í—˜ ì•½ê´€]ê³¼ ê´€ë ¨ëœ **êµ¬ì²´ì ì¸ ì‚¬ê³  ìƒí™©(ì‹œë‚˜ë¦¬ì˜¤)**ì„ ê°€ì •í•˜ê³ , ì´ ê²½ìš° ë³´ìƒì´ ê°€ëŠ¥í•œì§€ ë¬»ëŠ” ì§ˆë¬¸ì„ í•˜ë‚˜ë§Œ ë§Œë“œì„¸ìš”.

[ê·œì¹™]
1. "ì œê°€ ~í•œ ìƒí™©ì¸ë°ìš”," ì²˜ëŸ¼ êµ¬ì²´ì ì¸ ìƒí™©ì„ ë¬˜ì‚¬í•˜ì„¸ìš”.
2. ì˜ˆ: "ì£¼ì°¨ì¥ì—ì„œ ë¬¸ì„ ì—´ë‹¤ê°€ ì˜† ì°¨ë¥¼ ì‚´ì§ ê¸ì—ˆëŠ”ë°, ì´ê²ƒë„ ë³´ìƒë˜ë‚˜ìš”?"
3. ë°˜ë“œì‹œ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ë§Œë“œì„¸ìš”.

[ë³´í—˜ ì•½ê´€]
{text}

[ìƒì„± í˜•ì‹]
ì§ˆë¬¸: [ì§ˆë¬¸ë‚´ìš©]
ë‹µë³€: [ì•½ê´€ì„ ì ìš©í•˜ì—¬ ìƒí™©ì— ë§ê²Œ ì„¤ëª…í•œ ë‹µë³€]
"""

PROMPT_EASY = """
ë‹¹ì‹ ì€ **'ë³´í—˜ ìš©ì–´ë¥¼ ì „í˜€ ëª¨ë¥´ëŠ” ì‚¬íšŒ ì´ˆë…„ìƒ'**ì…ë‹ˆë‹¤.
ì œê³µëœ [ë³´í—˜ ì•½ê´€]ì˜ ë‚´ìš©ì„ ë¬»ë˜, ì „ë¬¸ ìš©ì–´(ì˜ˆ: ê¸°ì™•ì¦, ë©´ì±…ê¸ˆ)ë¥¼ ì“°ì§€ ë§ê³  **ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ** ì§ˆë¬¸í•˜ì„¸ìš”.

[ê·œì¹™]
1. ì „ë¬¸ ìš©ì–´ ëŒ€ì‹  "ê·¸ê±° ìˆì–ì•„ìš”", "ë‚´ê°€ ë‚´ì•¼ í•˜ëŠ” ëˆ" ê°™ì€ í‘œí˜„ì„ ì“°ì„¸ìš”.
2. ì˜ˆ: "ìê¸°ë¶€ë‹´ê¸ˆì´ ë­”ê°€ìš”?" (X) -> "ì‚¬ê³  ë‚˜ë©´ ì œê°€ ìŒ©ëˆìœ¼ë¡œ ë‚´ì•¼ í•˜ëŠ” ê¸ˆì•¡ì´ ì–¼ë§ˆì¸ê°€ìš”?" (O)
3. ë°˜ë“œì‹œ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ë§Œë“œì„¸ìš”.

[ë³´í—˜ ì•½ê´€]
{text}

[ìƒì„± í˜•ì‹]
ì§ˆë¬¸: [ì§ˆë¬¸ë‚´ìš©]
ë‹µë³€: [ì´ˆë³´ìë„ ì´í•´í•˜ê¸° ì‰½ê²Œ í’€ì–´ì„œ ì“´ ë‹µë³€]
"""

# -----------------------------------------------------------------------------
# 3. Robust API Call (ì§€ìˆ˜ ë°±ì˜¤í”„ ì ìš© + Rate Limit ëŒ€ì‘ ê°•í™”)
# -----------------------------------------------------------------------------
def call_gemini_api_robust(api_key, payload, max_retries=5):
    headers = {"Content-Type": "application/json"}
    base_delay = 2.0
    
    for attempt in range(max_retries + 1):
        try:
            response = requests.post(
                f"{GEMINI_API_URL}?key={api_key}",
                json=payload,
                headers=headers,
                timeout=30
            )
            
            if response.status_code == 200:
                return response.json()
            
            # 429(Rate Limit) -> ë” ê¸´ ëŒ€ê¸° ì‹œê°„
            if response.status_code == 429:
                # Rate Limitì˜ ê²½ìš° ë” ê¸´ ëŒ€ê¸° ì‹œê°„ (ìµœëŒ€ 30ì´ˆë¡œ ë‹¨ì¶•)
                wait_time = min(base_delay * (2 ** attempt) * 2 + random.uniform(1, 3), 30)
                if attempt < max_retries:
                    print(f"âš ï¸ Rate Limit (429) ë°œìƒ. {wait_time:.1f}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"âŒ Rate Limit (429) ì¬ì‹œë„ ì‹¤íŒ¨. None ë°˜í™˜")
                    return None
            
            # 500(Server Error) -> Retry
            if response.status_code >= 500:
                wait_time = base_delay * (2 ** attempt) + random.uniform(0, 1)
                if attempt < max_retries:
                    time.sleep(wait_time)
                    continue
            
            # 400(Bad Request) ë“±ì€ ì¦‰ì‹œ ì‹¤íŒ¨ ì²˜ë¦¬
            return None
            
        except Exception as e:
            wait_time = base_delay * (2 ** attempt)
            if attempt < max_retries:
                time.sleep(wait_time)
    
    return None

def parse_response(response_json, q_type, chunk_text, chunk_id):
    try:
        if 'candidates' not in response_json or not response_json['candidates']:
            return None
            
        candidate = response_json['candidates'][0]
        if 'content' not in candidate or 'parts' not in candidate['content']:
            return None
            
        content = candidate['content']['parts'][0]['text']
        
        lines = content.strip().split('\n')
        question = ""
        answer = ""
        
        for line in lines:
            if line.startswith("ì§ˆë¬¸:"):
                question = line.replace("ì§ˆë¬¸:", "").strip()
            elif line.startswith("ë‹µë³€:"):
                answer = line.replace("ë‹µë³€:", "").strip()
        
        if not question or not answer:
            return None
            
        return {
            "chunk_id": chunk_id,
            "instruction": question,
            "input": chunk_text,
            "output": answer,
            "type": q_type
        }
    except:
        return None

# -----------------------------------------------------------------------------
# 4. Main Logic
# -----------------------------------------------------------------------------
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--key_num", type=int, required=True, help="API Key Number (1-20)")
    parser.add_argument("--total_keys", type=int, default=1, help="Total number of keys used")
    parser.add_argument("--input", default="/home/pencilfoxs/0_Insurance_PF/01_Preprocessing/chunked_data.jsonl")
    parser.add_argument("--output_dir", default="generated_data")
    args = parser.parse_args()

    # 1. API í‚¤ ë¡œë“œ
    try:
        api_key = load_api_key(args.key_num)
        print(f"âœ… [Worker {args.key_num}] API Key Loaded")
    except Exception as e:
        print(f"âŒ [Worker {args.key_num}] Error: {e}")
        return

    # 2. ì²­í¬ ë¡œë“œ
    with open(args.input, 'r', encoding='utf-8') as f:
        all_chunks = [json.loads(line) for line in f]
    
    # 3. ë°ì´í„° ë¶„í•  (Sharding)
    # ì „ì²´ ë°ì´í„°ë¥¼ total_keysë¡œ ë‚˜ëˆ„ì–´ ë‚´ ëª«ë§Œ ê°€ì ¸ì˜´
    total_chunks = len(all_chunks)
    chunk_size = math.ceil(total_chunks / args.total_keys)
    start_idx = (args.key_num - 1) * chunk_size
    end_idx = min(start_idx + chunk_size, total_chunks)
    
    my_chunks = all_chunks[start_idx:end_idx]
    print(f"ğŸ“Š [Worker {args.key_num}] Assigned: {start_idx} ~ {end_idx-1} ({len(my_chunks)} chunks)")
    
    if not my_chunks:
        print(f"âœ… [Worker {args.key_num}] No chunks assigned. Exiting.")
        return

    # 4. ì¶œë ¥ íŒŒì¼ ì„¤ì • ë° Resume ì¤€ë¹„
    os.makedirs(args.output_dir, exist_ok=True)
    output_file = os.path.join(args.output_dir, f"dataset_part_{args.key_num}.json")
    
    processed_chunk_ids = set()
    dataset = []
    
    if os.path.exists(output_file):
        try:
            with open(output_file, 'r', encoding='utf-8') as f:
                dataset = json.load(f)
                # ì´ë¯¸ ì²˜ë¦¬ëœ chunk_id ìˆ˜ì§‘ (í•œ ì²­í¬ì— 3ê°œ ì§ˆë¬¸ì´ë¯€ë¡œ chunk_idë¡œ ì²´í¬)
                for item in dataset:
                    if 'chunk_id' in item:
                        processed_chunk_ids.add(item['chunk_id'])
            print(f"ğŸ“‚ [Worker {args.key_num}] Resuming: {len(processed_chunk_ids)} chunks already processed")
        except:
            print(f"âš ï¸ [Worker {args.key_num}] Output file load failed. Starting fresh.")
            dataset = []

    # 5. ìƒì„± ë£¨í”„
    prompts = [('fact', PROMPT_FACT), ('scenario', PROMPT_SCENARIO), ('easy', PROMPT_EASY)]
    
    # ì´ë¯¸ ì²˜ë¦¬ëœ ì²­í¬ëŠ” ê±´ë„ˆëœ€
    target_chunks = [c for c in my_chunks if c['chunk_id'] not in processed_chunk_ids]
    
    for i, chunk in enumerate(tqdm(target_chunks, desc=f"Worker {args.key_num}", position=args.key_num)):
        chunk_text = chunk['text']
        chunk_id = chunk['chunk_id']
        
        chunk_results = []
        for p_type, prompt_tmpl in prompts:
            payload = {
                "contents": [{"parts": [{"text": prompt_tmpl.format(text=chunk_text[:1500])}]}],
                "generationConfig": {
                    "temperature": 0.7 if p_type == 'scenario' else 0.4,
                    "maxOutputTokens": 2000
                }
            }
            
            # Rate Limit íšŒí”¼ë¥¼ ìœ„í•œ ìš”ì²­ ê°„ ê°„ê²© ì¶”ê°€ (0.2ì´ˆë¡œ ë‹¨ì¶•)
            time.sleep(0.2)
            
            result = call_gemini_api_robust(api_key, payload)
            if result:
                parsed = parse_response(result, p_type, chunk_text, chunk_id)
                if parsed:
                    chunk_results.append(parsed)
        
        # ê²°ê³¼ ì €ì¥ (í•˜ë‚˜ë¼ë„ ì„±ê³µí–ˆìœ¼ë©´)
        if chunk_results:
            dataset.extend(chunk_results)
            
        # 10ê°œ ì²­í¬ë§ˆë‹¤ íŒŒì¼ ì €ì¥ (ë°ì´í„° ì†ì‹¤ ë°©ì§€)
        if (i + 1) % 10 == 0:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(dataset, f, ensure_ascii=False, indent=2)

    # ìµœì¢… ì €ì¥
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)
        
    print(f"âœ… [Worker {args.key_num}] Completed! Total {len(dataset)} QA pairs generated.")

if __name__ == "__main__":
    main()
